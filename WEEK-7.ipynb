{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BetsLxcN63m"
      },
      "source": [
        "**Implement mini batch optimization technique to improve the performance of deep learning model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0tL32Wpbtmwd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary Packages\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout, Flatten\n",
        "from keras.layers import Conv2D, GlobalMaxPool2D\n",
        "from keras import backend as K\n",
        "from keras.src import optimizers\n",
        "from keras.src.layers import MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HonlwhZGtvol",
        "outputId": "3b04f027-6ce4-4dcf-8787-9d795f5a74c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "print(x_train.shape , y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GiJELRxPtzrC"
      },
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],28,28,1)\n",
        "x_test=x_test.reshape(x_test.shape[0],28,28,1)\n",
        "input_shape=(28,28,1)\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train)\n",
        "y_test=keras.utils.to_categorical(y_test)\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "batch_size=64\n",
        "num_classes =10\n",
        "epochs=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3kIAaM-st3Ye"
      },
      "outputs": [],
      "source": [
        "# Optimizer function\n",
        "\n",
        "def build_model(optimizer):\n",
        "  model=Sequential()\n",
        "  model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCtV0GaHt7gL",
        "outputId": "9e081046-4a36-496f-8abc-b9d7970fbb4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with optimizer: Adadelta\n",
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 2.2505 - accuracy: 0.1754 - val_loss: 2.1634 - val_accuracy: 0.3897\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 2.1166 - accuracy: 0.3584 - val_loss: 2.0125 - val_accuracy: 0.5852\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.9735 - accuracy: 0.4853 - val_loss: 1.8482 - val_accuracy: 0.6775\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.8202 - accuracy: 0.5630 - val_loss: 1.6768 - val_accuracy: 0.7316\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 1.6631 - accuracy: 0.6183 - val_loss: 1.5069 - val_accuracy: 0.7668\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 18s 19ms/step - loss: 1.5113 - accuracy: 0.6561 - val_loss: 1.3473 - val_accuracy: 0.7889\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 1.3735 - accuracy: 0.6817 - val_loss: 1.2033 - val_accuracy: 0.8043\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.2475 - accuracy: 0.7021 - val_loss: 1.0780 - val_accuracy: 0.8187\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.1450 - accuracy: 0.7222 - val_loss: 0.9724 - val_accuracy: 0.8284\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 1.0552 - accuracy: 0.7345 - val_loss: 0.8849 - val_accuracy: 0.8353\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: Adagrad\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 1.5722 - accuracy: 0.5632 - val_loss: 0.7661 - val_accuracy: 0.8410\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.7398 - accuracy: 0.7904 - val_loss: 0.4716 - val_accuracy: 0.8829\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.5704 - accuracy: 0.8307 - val_loss: 0.3895 - val_accuracy: 0.8995\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.4968 - accuracy: 0.8528 - val_loss: 0.3478 - val_accuracy: 0.9075\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.4523 - accuracy: 0.8656 - val_loss: 0.3209 - val_accuracy: 0.9128\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.4226 - accuracy: 0.8748 - val_loss: 0.3013 - val_accuracy: 0.9169\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.4045 - accuracy: 0.8803 - val_loss: 0.2859 - val_accuracy: 0.9211\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3843 - accuracy: 0.8860 - val_loss: 0.2733 - val_accuracy: 0.9242\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3641 - accuracy: 0.8909 - val_loss: 0.2620 - val_accuracy: 0.9263\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.3555 - accuracy: 0.8953 - val_loss: 0.2531 - val_accuracy: 0.9283\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: Adam\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.2466 - accuracy: 0.9252 - val_loss: 0.0785 - val_accuracy: 0.9742\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0981 - accuracy: 0.9705 - val_loss: 0.0558 - val_accuracy: 0.9815\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0711 - accuracy: 0.9776 - val_loss: 0.0460 - val_accuracy: 0.9838\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0591 - accuracy: 0.9818 - val_loss: 0.0409 - val_accuracy: 0.9867\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0491 - accuracy: 0.9844 - val_loss: 0.0414 - val_accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.0369 - val_accuracy: 0.9879\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0394 - accuracy: 0.9872 - val_loss: 0.0339 - val_accuracy: 0.9877\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.0344 - val_accuracy: 0.9892\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.0369 - val_accuracy: 0.9883\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: RMSprop\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.2474 - accuracy: 0.9236 - val_loss: 0.0790 - val_accuracy: 0.9750\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0954 - accuracy: 0.9711 - val_loss: 0.0507 - val_accuracy: 0.9823\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 0.0435 - val_accuracy: 0.9838\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 0.0398 - val_accuracy: 0.9859\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0394 - val_accuracy: 0.9856\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.0353 - val_accuracy: 0.9872\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.0461 - accuracy: 0.9859 - val_loss: 0.0415 - val_accuracy: 0.9871\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0365 - val_accuracy: 0.9878\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0377 - val_accuracy: 0.9873\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 9s 9ms/step - loss: 0.0382 - accuracy: 0.9882 - val_loss: 0.0385 - val_accuracy: 0.9891\n",
            "\n",
            "\n",
            "\n",
            "Training with optimizer: SGD\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.7962 - accuracy: 0.7603 - val_loss: 0.3039 - val_accuracy: 0.9150\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3795 - accuracy: 0.8845 - val_loss: 0.2267 - val_accuracy: 0.9350\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.3106 - accuracy: 0.9067 - val_loss: 0.1846 - val_accuracy: 0.9451\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.2648 - accuracy: 0.9206 - val_loss: 0.1597 - val_accuracy: 0.9530\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.2413 - accuracy: 0.9273 - val_loss: 0.1438 - val_accuracy: 0.9568\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2200 - accuracy: 0.9347 - val_loss: 0.1324 - val_accuracy: 0.9612\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 0.2057 - accuracy: 0.9373 - val_loss: 0.1255 - val_accuracy: 0.9630\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1940 - accuracy: 0.9419 - val_loss: 0.1147 - val_accuracy: 0.9658\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1870 - accuracy: 0.9432 - val_loss: 0.1095 - val_accuracy: 0.9670\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.1771 - accuracy: 0.9471 - val_loss: 0.1038 - val_accuracy: 0.9689\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trying 5 Optimizers\n",
        "\n",
        "optimizers = ['Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD']\n",
        "\n",
        "for optimizer_name in optimizers:\n",
        "    print(f\"Training with optimizer: {optimizer_name}\")\n",
        "    model = build_model(optimizer_name)\n",
        "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "    print('\\n\\n')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
