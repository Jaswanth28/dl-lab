{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression mlp model for the abalone dataset\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the keras model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the keras model\n",
    "# model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the keras model on the dataset\n",
    "# model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.81\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate on test set\n",
    "# yhat = model.predict(X_test)\n",
    "# error = mean_absolute_error(y_test, yhat)\n",
    "# print('MAE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification mlp model for the abalone dataset\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into input (X) and output (y) variables\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode strings to integer\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "n_class = len(unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From c:\\Users\\Jaswanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "88/88 - 0s - loss: 3.2333 - 479ms/epoch - 5ms/step\n",
      "Epoch 2/150\n",
      "88/88 - 0s - loss: 2.8692 - 63ms/epoch - 716us/step\n",
      "Epoch 3/150\n",
      "88/88 - 0s - loss: 2.5835 - 60ms/epoch - 682us/step\n",
      "Epoch 4/150\n",
      "88/88 - 0s - loss: 2.4706 - 64ms/epoch - 727us/step\n",
      "Epoch 5/150\n",
      "88/88 - 0s - loss: 2.4000 - 101ms/epoch - 1ms/step\n",
      "Epoch 6/150\n",
      "88/88 - 0s - loss: 2.3388 - 89ms/epoch - 1ms/step\n",
      "Epoch 7/150\n",
      "88/88 - 0s - loss: 2.2899 - 103ms/epoch - 1ms/step\n",
      "Epoch 8/150\n",
      "88/88 - 0s - loss: 2.2528 - 95ms/epoch - 1ms/step\n",
      "Epoch 9/150\n",
      "88/88 - 0s - loss: 2.2285 - 89ms/epoch - 1ms/step\n",
      "Epoch 10/150\n",
      "88/88 - 0s - loss: 2.2062 - 65ms/epoch - 737us/step\n",
      "Epoch 11/150\n",
      "88/88 - 0s - loss: 2.1912 - 61ms/epoch - 695us/step\n",
      "Epoch 12/150\n",
      "88/88 - 0s - loss: 2.1785 - 59ms/epoch - 669us/step\n",
      "Epoch 13/150\n",
      "88/88 - 0s - loss: 2.1657 - 60ms/epoch - 678us/step\n",
      "Epoch 14/150\n",
      "88/88 - 0s - loss: 2.1565 - 58ms/epoch - 661us/step\n",
      "Epoch 15/150\n",
      "88/88 - 0s - loss: 2.1476 - 57ms/epoch - 648us/step\n",
      "Epoch 16/150\n",
      "88/88 - 0s - loss: 2.1376 - 59ms/epoch - 670us/step\n",
      "Epoch 17/150\n",
      "88/88 - 0s - loss: 2.1287 - 57ms/epoch - 648us/step\n",
      "Epoch 18/150\n",
      "88/88 - 0s - loss: 2.1214 - 58ms/epoch - 659us/step\n",
      "Epoch 19/150\n",
      "88/88 - 0s - loss: 2.1135 - 68ms/epoch - 773us/step\n",
      "Epoch 20/150\n",
      "88/88 - 0s - loss: 2.1066 - 87ms/epoch - 986us/step\n",
      "Epoch 21/150\n",
      "88/88 - 0s - loss: 2.0984 - 91ms/epoch - 1ms/step\n",
      "Epoch 22/150\n",
      "88/88 - 0s - loss: 2.0926 - 110ms/epoch - 1ms/step\n",
      "Epoch 23/150\n",
      "88/88 - 0s - loss: 2.0876 - 97ms/epoch - 1ms/step\n",
      "Epoch 24/150\n",
      "88/88 - 0s - loss: 2.0805 - 87ms/epoch - 986us/step\n",
      "Epoch 25/150\n",
      "88/88 - 0s - loss: 2.0732 - 78ms/epoch - 889us/step\n",
      "Epoch 26/150\n",
      "88/88 - 0s - loss: 2.0670 - 78ms/epoch - 891us/step\n",
      "Epoch 27/150\n",
      "88/88 - 0s - loss: 2.0604 - 99ms/epoch - 1ms/step\n",
      "Epoch 28/150\n",
      "88/88 - 0s - loss: 2.0566 - 83ms/epoch - 943us/step\n",
      "Epoch 29/150\n",
      "88/88 - 0s - loss: 2.0512 - 87ms/epoch - 989us/step\n",
      "Epoch 30/150\n",
      "88/88 - 0s - loss: 2.0457 - 85ms/epoch - 965us/step\n",
      "Epoch 31/150\n",
      "88/88 - 0s - loss: 2.0418 - 105ms/epoch - 1ms/step\n",
      "Epoch 32/150\n",
      "88/88 - 0s - loss: 2.0360 - 86ms/epoch - 981us/step\n",
      "Epoch 33/150\n",
      "88/88 - 0s - loss: 2.0304 - 89ms/epoch - 1ms/step\n",
      "Epoch 34/150\n",
      "88/88 - 0s - loss: 2.0267 - 85ms/epoch - 963us/step\n",
      "Epoch 35/150\n",
      "88/88 - 0s - loss: 2.0236 - 86ms/epoch - 983us/step\n",
      "Epoch 36/150\n",
      "88/88 - 0s - loss: 2.0185 - 90ms/epoch - 1ms/step\n",
      "Epoch 37/150\n",
      "88/88 - 0s - loss: 2.0163 - 84ms/epoch - 957us/step\n",
      "Epoch 38/150\n",
      "88/88 - 0s - loss: 2.0126 - 86ms/epoch - 980us/step\n",
      "Epoch 39/150\n",
      "88/88 - 0s - loss: 2.0104 - 81ms/epoch - 916us/step\n",
      "Epoch 40/150\n",
      "88/88 - 0s - loss: 2.0055 - 73ms/epoch - 824us/step\n",
      "Epoch 41/150\n",
      "88/88 - 0s - loss: 2.0027 - 61ms/epoch - 693us/step\n",
      "Epoch 42/150\n",
      "88/88 - 0s - loss: 2.0010 - 62ms/epoch - 704us/step\n",
      "Epoch 43/150\n",
      "88/88 - 0s - loss: 1.9971 - 61ms/epoch - 688us/step\n",
      "Epoch 44/150\n",
      "88/88 - 0s - loss: 1.9945 - 60ms/epoch - 684us/step\n",
      "Epoch 45/150\n",
      "88/88 - 0s - loss: 1.9934 - 62ms/epoch - 702us/step\n",
      "Epoch 46/150\n",
      "88/88 - 0s - loss: 1.9903 - 63ms/epoch - 716us/step\n",
      "Epoch 47/150\n",
      "88/88 - 0s - loss: 1.9902 - 62ms/epoch - 701us/step\n",
      "Epoch 48/150\n",
      "88/88 - 0s - loss: 1.9860 - 63ms/epoch - 718us/step\n",
      "Epoch 49/150\n",
      "88/88 - 0s - loss: 1.9848 - 62ms/epoch - 709us/step\n",
      "Epoch 50/150\n",
      "88/88 - 0s - loss: 1.9848 - 62ms/epoch - 704us/step\n",
      "Epoch 51/150\n",
      "88/88 - 0s - loss: 1.9828 - 64ms/epoch - 727us/step\n",
      "Epoch 52/150\n",
      "88/88 - 0s - loss: 1.9789 - 61ms/epoch - 696us/step\n",
      "Epoch 53/150\n",
      "88/88 - 0s - loss: 1.9787 - 65ms/epoch - 733us/step\n",
      "Epoch 54/150\n",
      "88/88 - 0s - loss: 1.9772 - 62ms/epoch - 706us/step\n",
      "Epoch 55/150\n",
      "88/88 - 0s - loss: 1.9766 - 83ms/epoch - 942us/step\n",
      "Epoch 56/150\n",
      "88/88 - 0s - loss: 1.9751 - 68ms/epoch - 772us/step\n",
      "Epoch 57/150\n",
      "88/88 - 0s - loss: 1.9743 - 61ms/epoch - 693us/step\n",
      "Epoch 58/150\n",
      "88/88 - 0s - loss: 1.9719 - 62ms/epoch - 705us/step\n",
      "Epoch 59/150\n",
      "88/88 - 0s - loss: 1.9712 - 62ms/epoch - 704us/step\n",
      "Epoch 60/150\n",
      "88/88 - 0s - loss: 1.9715 - 82ms/epoch - 932us/step\n",
      "Epoch 61/150\n",
      "88/88 - 0s - loss: 1.9674 - 101ms/epoch - 1ms/step\n",
      "Epoch 62/150\n",
      "88/88 - 0s - loss: 1.9707 - 96ms/epoch - 1ms/step\n",
      "Epoch 63/150\n",
      "88/88 - 0s - loss: 1.9671 - 86ms/epoch - 977us/step\n",
      "Epoch 64/150\n",
      "88/88 - 0s - loss: 1.9667 - 62ms/epoch - 705us/step\n",
      "Epoch 65/150\n",
      "88/88 - 0s - loss: 1.9655 - 60ms/epoch - 682us/step\n",
      "Epoch 66/150\n",
      "88/88 - 0s - loss: 1.9646 - 93ms/epoch - 1ms/step\n",
      "Epoch 67/150\n",
      "88/88 - 0s - loss: 1.9627 - 95ms/epoch - 1ms/step\n",
      "Epoch 68/150\n",
      "88/88 - 0s - loss: 1.9616 - 92ms/epoch - 1ms/step\n",
      "Epoch 69/150\n",
      "88/88 - 0s - loss: 1.9619 - 106ms/epoch - 1ms/step\n",
      "Epoch 70/150\n",
      "88/88 - 0s - loss: 1.9608 - 82ms/epoch - 932us/step\n",
      "Epoch 71/150\n",
      "88/88 - 0s - loss: 1.9618 - 73ms/epoch - 830us/step\n",
      "Epoch 72/150\n",
      "88/88 - 0s - loss: 1.9618 - 75ms/epoch - 852us/step\n",
      "Epoch 73/150\n",
      "88/88 - 0s - loss: 1.9602 - 70ms/epoch - 795us/step\n",
      "Epoch 74/150\n",
      "88/88 - 0s - loss: 1.9622 - 81ms/epoch - 921us/step\n",
      "Epoch 75/150\n",
      "88/88 - 0s - loss: 1.9573 - 78ms/epoch - 886us/step\n",
      "Epoch 76/150\n",
      "88/88 - 0s - loss: 1.9581 - 75ms/epoch - 852us/step\n",
      "Epoch 77/150\n",
      "88/88 - 0s - loss: 1.9569 - 82ms/epoch - 932us/step\n",
      "Epoch 78/150\n",
      "88/88 - 0s - loss: 1.9557 - 76ms/epoch - 864us/step\n",
      "Epoch 79/150\n",
      "88/88 - 0s - loss: 1.9569 - 67ms/epoch - 761us/step\n",
      "Epoch 80/150\n",
      "88/88 - 0s - loss: 1.9547 - 87ms/epoch - 989us/step\n",
      "Epoch 81/150\n",
      "88/88 - 0s - loss: 1.9542 - 76ms/epoch - 864us/step\n",
      "Epoch 82/150\n",
      "88/88 - 0s - loss: 1.9545 - 61ms/epoch - 693us/step\n",
      "Epoch 83/150\n",
      "88/88 - 0s - loss: 1.9526 - 60ms/epoch - 682us/step\n",
      "Epoch 84/150\n",
      "88/88 - 0s - loss: 1.9539 - 61ms/epoch - 693us/step\n",
      "Epoch 85/150\n",
      "88/88 - 0s - loss: 1.9514 - 63ms/epoch - 716us/step\n",
      "Epoch 86/150\n",
      "88/88 - 0s - loss: 1.9525 - 61ms/epoch - 693us/step\n",
      "Epoch 87/150\n",
      "88/88 - 0s - loss: 1.9512 - 59ms/epoch - 670us/step\n",
      "Epoch 88/150\n",
      "88/88 - 0s - loss: 1.9525 - 65ms/epoch - 738us/step\n",
      "Epoch 89/150\n",
      "88/88 - 0s - loss: 1.9517 - 64ms/epoch - 727us/step\n",
      "Epoch 90/150\n",
      "88/88 - 0s - loss: 1.9514 - 60ms/epoch - 682us/step\n",
      "Epoch 91/150\n",
      "88/88 - 0s - loss: 1.9506 - 67ms/epoch - 761us/step\n",
      "Epoch 92/150\n",
      "88/88 - 0s - loss: 1.9479 - 60ms/epoch - 682us/step\n",
      "Epoch 93/150\n",
      "88/88 - 0s - loss: 1.9489 - 61ms/epoch - 693us/step\n",
      "Epoch 94/150\n",
      "88/88 - 0s - loss: 1.9490 - 62ms/epoch - 705us/step\n",
      "Epoch 95/150\n",
      "88/88 - 0s - loss: 1.9473 - 63ms/epoch - 716us/step\n",
      "Epoch 96/150\n",
      "88/88 - 0s - loss: 1.9478 - 63ms/epoch - 716us/step\n",
      "Epoch 97/150\n",
      "88/88 - 0s - loss: 1.9476 - 70ms/epoch - 795us/step\n",
      "Epoch 98/150\n",
      "88/88 - 0s - loss: 1.9486 - 79ms/epoch - 898us/step\n",
      "Epoch 99/150\n",
      "88/88 - 0s - loss: 1.9476 - 84ms/epoch - 955us/step\n",
      "Epoch 100/150\n",
      "88/88 - 0s - loss: 1.9461 - 97ms/epoch - 1ms/step\n",
      "Epoch 101/150\n",
      "88/88 - 0s - loss: 1.9465 - 70ms/epoch - 795us/step\n",
      "Epoch 102/150\n",
      "88/88 - 0s - loss: 1.9447 - 63ms/epoch - 716us/step\n",
      "Epoch 103/150\n",
      "88/88 - 0s - loss: 1.9444 - 65ms/epoch - 739us/step\n",
      "Epoch 104/150\n",
      "88/88 - 0s - loss: 1.9463 - 73ms/epoch - 830us/step\n",
      "Epoch 105/150\n",
      "88/88 - 0s - loss: 1.9442 - 71ms/epoch - 807us/step\n",
      "Epoch 106/150\n",
      "88/88 - 0s - loss: 1.9437 - 69ms/epoch - 784us/step\n",
      "Epoch 107/150\n",
      "88/88 - 0s - loss: 1.9439 - 69ms/epoch - 784us/step\n",
      "Epoch 108/150\n",
      "88/88 - 0s - loss: 1.9437 - 69ms/epoch - 784us/step\n",
      "Epoch 109/150\n",
      "88/88 - 0s - loss: 1.9435 - 68ms/epoch - 773us/step\n",
      "Epoch 110/150\n",
      "88/88 - 0s - loss: 1.9415 - 67ms/epoch - 761us/step\n",
      "Epoch 111/150\n",
      "88/88 - 0s - loss: 1.9422 - 63ms/epoch - 716us/step\n",
      "Epoch 112/150\n",
      "88/88 - 0s - loss: 1.9440 - 73ms/epoch - 830us/step\n",
      "Epoch 113/150\n",
      "88/88 - 0s - loss: 1.9412 - 69ms/epoch - 784us/step\n",
      "Epoch 114/150\n",
      "88/88 - 0s - loss: 1.9409 - 68ms/epoch - 773us/step\n",
      "Epoch 115/150\n",
      "88/88 - 0s - loss: 1.9406 - 65ms/epoch - 739us/step\n",
      "Epoch 116/150\n",
      "88/88 - 0s - loss: 1.9422 - 62ms/epoch - 705us/step\n",
      "Epoch 117/150\n",
      "88/88 - 0s - loss: 1.9424 - 63ms/epoch - 716us/step\n",
      "Epoch 118/150\n",
      "88/88 - 0s - loss: 1.9413 - 65ms/epoch - 739us/step\n",
      "Epoch 119/150\n",
      "88/88 - 0s - loss: 1.9388 - 61ms/epoch - 689us/step\n",
      "Epoch 120/150\n",
      "88/88 - 0s - loss: 1.9419 - 60ms/epoch - 682us/step\n",
      "Epoch 121/150\n",
      "88/88 - 0s - loss: 1.9414 - 61ms/epoch - 693us/step\n",
      "Epoch 122/150\n",
      "88/88 - 0s - loss: 1.9389 - 58ms/epoch - 659us/step\n",
      "Epoch 123/150\n",
      "88/88 - 0s - loss: 1.9408 - 62ms/epoch - 705us/step\n",
      "Epoch 124/150\n",
      "88/88 - 0s - loss: 1.9409 - 61ms/epoch - 693us/step\n",
      "Epoch 125/150\n",
      "88/88 - 0s - loss: 1.9390 - 61ms/epoch - 693us/step\n",
      "Epoch 126/150\n",
      "88/88 - 0s - loss: 1.9377 - 59ms/epoch - 670us/step\n",
      "Epoch 127/150\n",
      "88/88 - 0s - loss: 1.9378 - 60ms/epoch - 682us/step\n",
      "Epoch 128/150\n",
      "88/88 - 0s - loss: 1.9384 - 60ms/epoch - 682us/step\n",
      "Epoch 129/150\n",
      "88/88 - 0s - loss: 1.9388 - 61ms/epoch - 693us/step\n",
      "Epoch 130/150\n",
      "88/88 - 0s - loss: 1.9381 - 61ms/epoch - 693us/step\n",
      "Epoch 131/150\n",
      "88/88 - 0s - loss: 1.9356 - 63ms/epoch - 716us/step\n",
      "Epoch 132/150\n",
      "88/88 - 0s - loss: 1.9381 - 61ms/epoch - 693us/step\n",
      "Epoch 133/150\n",
      "88/88 - 0s - loss: 1.9354 - 60ms/epoch - 682us/step\n",
      "Epoch 134/150\n",
      "88/88 - 0s - loss: 1.9370 - 62ms/epoch - 705us/step\n",
      "Epoch 135/150\n",
      "88/88 - 0s - loss: 1.9349 - 59ms/epoch - 670us/step\n",
      "Epoch 136/150\n",
      "88/88 - 0s - loss: 1.9340 - 78ms/epoch - 884us/step\n",
      "Epoch 137/150\n",
      "88/88 - 0s - loss: 1.9356 - 60ms/epoch - 683us/step\n",
      "Epoch 138/150\n",
      "88/88 - 0s - loss: 1.9346 - 59ms/epoch - 671us/step\n",
      "Epoch 139/150\n",
      "88/88 - 0s - loss: 1.9338 - 61ms/epoch - 693us/step\n",
      "Epoch 140/150\n",
      "88/88 - 0s - loss: 1.9358 - 60ms/epoch - 681us/step\n",
      "Epoch 141/150\n",
      "88/88 - 0s - loss: 1.9315 - 67ms/epoch - 761us/step\n",
      "Epoch 142/150\n",
      "88/88 - 0s - loss: 1.9335 - 79ms/epoch - 897us/step\n",
      "Epoch 143/150\n",
      "88/88 - 0s - loss: 1.9327 - 71ms/epoch - 807us/step\n",
      "Epoch 144/150\n",
      "88/88 - 0s - loss: 1.9319 - 78ms/epoch - 886us/step\n",
      "Epoch 145/150\n",
      "88/88 - 0s - loss: 1.9329 - 63ms/epoch - 717us/step\n",
      "Epoch 146/150\n",
      "88/88 - 0s - loss: 1.9327 - 59ms/epoch - 670us/step\n",
      "Epoch 147/150\n",
      "88/88 - 0s - loss: 1.9328 - 60ms/epoch - 682us/step\n",
      "Epoch 148/150\n",
      "88/88 - 0s - loss: 1.9317 - 61ms/epoch - 693us/step\n",
      "Epoch 149/150\n",
      "88/88 - 0s - loss: 1.9308 - 77ms/epoch - 875us/step\n",
      "Epoch 150/150\n",
      "88/88 - 0s - loss: 1.9320 - 81ms/epoch - 919us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26960771390>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 708us/step\n",
      "Accuracy: 0.275\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "yhat = model.predict(X_test)\n",
    "yhat = argmax(yhat, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
